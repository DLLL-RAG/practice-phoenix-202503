{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb346ad9-df9b-4c31-b94d-7ba3db8f6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.arize.com/phoenix/evaluation/evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33bbb1ad-dd6e-4d7a-be95-6ed16ad36fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: default\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://phoenix:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(\n",
    "  project_name=\"default\",\n",
    "  endpoint=\"http://phoenix:6006/v1/traces\",\n",
    "  # auto_instrument=True # Auto-instrument your app based on installed dependencie\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f890563a-cdf8-454a-a5bd-2d16a41e7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9b175a-7af5-4617-be1c-5126ccdf2892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.</td>\n",
       "      <td>Where is the Eiffel Tower located?</td>\n",
       "      <td>The Eiffel Tower is located in Paris, France.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.</td>\n",
       "      <td>How long is the Great Wall of China?</td>\n",
       "      <td>The Great Wall of China is approximately 13,171 miles (21,196 kilometers) long.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.</td>\n",
       "      <td>What is the largest tropical rainforest?</td>\n",
       "      <td>The Amazon rainforest is the largest tropical rainforest in the world. It is home to the largest number of plant and animal species in the world.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.</td>\n",
       "      <td>Which is the highest mountain on Earth?</td>\n",
       "      <td>Mount Everest, standing at 29,029 feet (8,848 meters), is the highest mountain on Earth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.</td>\n",
       "      <td>What is the longest river in the world?</td>\n",
       "      <td>The Nile River, at 6,650 kilometers (4,132 miles), is the longest river in the world.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                               reference  \\\n",
       "0                                                                                The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.   \n",
       "1                                                 The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.   \n",
       "2                       The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.   \n",
       "3                                       Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.   \n",
       "4  The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.   \n",
       "\n",
       "                                      query  \\\n",
       "0        Where is the Eiffel Tower located?   \n",
       "1      How long is the Great Wall of China?   \n",
       "2  What is the largest tropical rainforest?   \n",
       "3   Which is the highest mountain on Earth?   \n",
       "4   What is the longest river in the world?   \n",
       "\n",
       "                                                                                                                                            response  \n",
       "0                                                                                                      The Eiffel Tower is located in Paris, France.  \n",
       "1                                                                    The Great Wall of China is approximately 13,171 miles (21,196 kilometers) long.  \n",
       "2  The Amazon rainforest is the largest tropical rainforest in the world. It is home to the largest number of plant and animal species in the world.  \n",
       "3                                                           Mount Everest, standing at 29,029 feet (8,848 meters), is the highest mountain on Earth.  \n",
       "4                                                              The Nile River, at 6,650 kilometers (4,132 miles), is the longest river in the world.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ë®≠ÂÆöÈ°ØÁ§∫ÈÅ∏È†ÖÔºåÁ¢∫‰øù‰∏çÊúÉÊà™Êñ∑Â≠ó‰∏≤\n",
    "pd.set_option(\"display.max_colwidth\", None)  # ‰ΩøÂæóÂ≠ó‰∏≤Ê¨Ñ‰ΩçÂÆåÊï¥È°ØÁ§∫\n",
    "pd.set_option(\"display.max_columns\", None)   # È°ØÁ§∫ÊâÄÊúâÊ¨Ñ‰Ωç\n",
    "pd.set_option(\"display.width\", None)         # ËÆìËº∏Âá∫ÂØ¨Â∫¶Ëá™ÂãïË™øÊï¥\n",
    "\n",
    "# Â¶ÇÊûúÈúÄË¶ÅÈ°ØÁ§∫Êõ¥Â§öÂàóÔºåÂèØ‰ª•Ë¶ñÈúÄÊ±ÇË™øÊï¥Ôºö\n",
    "# pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"reference\": \"The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.\",\n",
    "            \"query\": \"Where is the Eiffel Tower located?\",\n",
    "            \"response\": \"The Eiffel Tower is located in Paris, France.\",\n",
    "        },\n",
    "        {\n",
    "            \"reference\": \"The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.\",\n",
    "            \"query\": \"How long is the Great Wall of China?\",\n",
    "            \"response\": \"The Great Wall of China is approximately 13,171 miles (21,196 kilometers) long.\",\n",
    "        },\n",
    "        {\n",
    "            \"reference\": \"The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.\",\n",
    "            \"query\": \"What is the largest tropical rainforest?\",\n",
    "            \"response\": \"The Amazon rainforest is the largest tropical rainforest in the world. It is home to the largest number of plant and animal species in the world.\",\n",
    "        },\n",
    "        {\n",
    "            \"reference\": \"Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.\",\n",
    "            \"query\": \"Which is the highest mountain on Earth?\",\n",
    "            \"response\": \"Mount Everest, standing at 29,029 feet (8,848 meters), is the highest mountain on Earth.\",\n",
    "        },\n",
    "        {\n",
    "            \"reference\": \"The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.\",\n",
    "            \"query\": \"What is the longest river in the world?\",\n",
    "            \"response\": \"The Nile River, at 6,650 kilometers (4,132 miles), is the longest river in the world.\",\n",
    "        },\n",
    "        {\n",
    "            \"reference\": \"The Mona Lisa was painted by Leonardo da Vinci. It is considered an archetypal masterpiece of the Italian Renaissance and has been described as 'the best known, the most visited, the most written about, the most sung about, the most parodied work of art in the world'.\",\n",
    "            \"query\": \"Who painted the Mona Lisa?\",\n",
    "            \"response\": \"The Mona Lisa was painted by the Italian Renaissance artist Leonardo da Vinci.\",\n",
    "        },\n",
    "        {\n",
    "            \"reference\": \"The human body has 206 bones. These bones provide structure, protect organs, anchor muscles, and store calcium.\",\n",
    "            \"query\": \"How many bones are in the human body?\",\n",
    "            \"response\": \"The adult human body typically has 256 bones.\",\n",
    "        },\n",
    "        {\n",
    "            \"reference\": \"Jupiter is the largest planet in our solar system. It is a gas giant with a mass more than two and a half times that of all the other planets in the solar system combined.\",\n",
    "            \"query\": \"Which planet is the largest in our solar system?\",\n",
    "            \"response\": \"Jupiter is the largest planet in our solar system.\",\n",
    "        },\n",
    "        {\n",
    "            \"reference\": \"William Shakespeare wrote 'Romeo and Juliet'. It is a tragedy about two young star-crossed lovers whose deaths ultimately reconcile their feuding families.\",\n",
    "            \"query\": \"Who wrote 'Romeo and Juliet'?\",\n",
    "            \"response\": \"The play 'Romeo and Juliet' was written by William Shakespeare.\",\n",
    "        },\n",
    "        {\n",
    "            \"reference\": \"The first moon landing occurred in 1969. On July 20, 1969, American astronauts Neil Armstrong and Edwin 'Buzz' Aldrin became the first humans to land on the moon as part of the Apollo 11 mission.\",\n",
    "            \"query\": \"When did the first moon landing occur?\",\n",
    "            \"response\": \"The first moon landing took place on July 20, 1969.\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03d5e7c-1ab9-4658-95fc-755b23b05c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944912adf909426d825cb1f444ed777a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "run_evals |          | 0/20 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 5: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 6: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 5: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 6: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 7: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 5: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 6: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 7: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 5: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 5: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 5: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 6: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 7: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 5: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 6: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 7: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 8: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 2: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 7: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 3: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 8: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 8: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 9: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 10: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 4: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 5: raised APIConnectionError('Connection error.')\n",
      "Requeuing...\n",
      "Retries exhausted after 11 attempts: Connection error.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from phoenix.evals import HallucinationEvaluator, OpenAIModel, QAEvaluator, run_evals\n",
    "\n",
    "nest_asyncio.apply()  # This is needed for concurrency in notebook environments\n",
    "\n",
    "# Set your OpenAI API key\n",
    "eval_model = OpenAIModel(model=\"o1\", api_key=os.getenv(\"OPENAI_API_KEY\"), base_url=os.getenv(\"OPENAI_API_BASE\"))\n",
    "\n",
    "# Define your evaluators\n",
    "hallucination_evaluator = HallucinationEvaluator(eval_model)\n",
    "qa_evaluator = QAEvaluator(eval_model)\n",
    "\n",
    "# We have to make some minor changes to our dataframe to use the column names expected by our evaluators\n",
    "# for `hallucination_evaluator` the input df needs to have columns 'output', 'input', 'context'\n",
    "# for `qa_evaluator` the input df needs to have columns 'output', 'input', 'reference'\n",
    "df[\"context\"] = df[\"reference\"]\n",
    "df.rename(columns={\"query\": \"input\", \"response\": \"output\"}, inplace=True)\n",
    "assert all(column in df.columns for column in [\"output\", \"input\", \"context\", \"reference\"])\n",
    "\n",
    "# Run the evaluators, each evaluator will return a dataframe with evaluation results\n",
    "# We upload the evaluation results to Phoenix in the next step\n",
    "hallucination_eval_df, qa_eval_df = run_evals(\n",
    "    dataframe=df, evaluators=[hallucination_evaluator, qa_evaluator], provide_explanation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc526f5-1f97-4f9e-9eca-0885d5221ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>context</th>\n",
       "      <th>hallucination_eval</th>\n",
       "      <th>hallucination_explanation</th>\n",
       "      <th>qa_eval</th>\n",
       "      <th>qa_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.</td>\n",
       "      <td>Where is the Eiffel Tower located?</td>\n",
       "      <td>The Eiffel Tower is located in Paris, France.</td>\n",
       "      <td>The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.</td>\n",
       "      <td>How long is the Great Wall of China?</td>\n",
       "      <td>The Great Wall of China is approximately 13,171 miles (21,196 kilometers) long.</td>\n",
       "      <td>The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.</td>\n",
       "      <td>What is the largest tropical rainforest?</td>\n",
       "      <td>The Amazon rainforest is the largest tropical rainforest in the world. It is home to the largest number of plant and animal species in the world.</td>\n",
       "      <td>The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.</td>\n",
       "      <td>Which is the highest mountain on Earth?</td>\n",
       "      <td>Mount Everest, standing at 29,029 feet (8,848 meters), is the highest mountain on Earth.</td>\n",
       "      <td>Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.</td>\n",
       "      <td>What is the longest river in the world?</td>\n",
       "      <td>The Nile River, at 6,650 kilometers (4,132 miles), is the longest river in the world.</td>\n",
       "      <td>The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                               reference  \\\n",
       "0                                                                                The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.   \n",
       "1                                                 The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.   \n",
       "2                       The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.   \n",
       "3                                       Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.   \n",
       "4  The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.   \n",
       "\n",
       "                                      input  \\\n",
       "0        Where is the Eiffel Tower located?   \n",
       "1      How long is the Great Wall of China?   \n",
       "2  What is the largest tropical rainforest?   \n",
       "3   Which is the highest mountain on Earth?   \n",
       "4   What is the longest river in the world?   \n",
       "\n",
       "                                                                                                                                              output  \\\n",
       "0                                                                                                      The Eiffel Tower is located in Paris, France.   \n",
       "1                                                                    The Great Wall of China is approximately 13,171 miles (21,196 kilometers) long.   \n",
       "2  The Amazon rainforest is the largest tropical rainforest in the world. It is home to the largest number of plant and animal species in the world.   \n",
       "3                                                           Mount Everest, standing at 29,029 feet (8,848 meters), is the highest mountain on Earth.   \n",
       "4                                                              The Nile River, at 6,650 kilometers (4,132 miles), is the longest river in the world.   \n",
       "\n",
       "                                                                                                                                                                                                 context  \\\n",
       "0                                                                                The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.   \n",
       "1                                                 The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.   \n",
       "2                       The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.   \n",
       "3                                       Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.   \n",
       "4  The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.   \n",
       "\n",
       "  hallucination_eval hallucination_explanation qa_eval qa_explanation  \n",
       "0               None                      None    None           None  \n",
       "1               None                      None    None           None  \n",
       "2               None                      None    None           None  \n",
       "3               None                      None    None           None  \n",
       "4               None                      None    None           None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = df.copy()\n",
    "results_df[\"hallucination_eval\"] = hallucination_eval_df[\"label\"]\n",
    "results_df[\"hallucination_explanation\"] = hallucination_eval_df[\"explanation\"]\n",
    "results_df[\"qa_eval\"] = qa_eval_df[\"label\"]\n",
    "results_df[\"qa_explanation\"] = qa_eval_df[\"explanation\"]\n",
    "\n",
    "# È°ØÁ§∫Ââç 5 Á≠ÜË≥áÊñôÔºå‰∏¶Á¢∫‰øùÊ¨Ñ‰ΩçÂÖßÂÆπ‰∏çË¢´Êà™Êñ∑\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e279a33-fcf0-4192-929b-bcefedc2548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FactualityEvaluator ‰∏çÂ≠òÂú®ÔºåÂ∞áË∑≥ÈÅéÊ≠§Ë©ï‰º∞Âô®„ÄÇ\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f945880d9daa4aec93e23e940f2ff477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "run_evals |          | 0/40 (0.0%) | ‚è≥ 00:00<? | ?it/s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in worker on attempt 1: raised InternalServerError('<!DOCTYPE html>\\n<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\\n<head>\\n\\n\\n<title>farm-bottom-mentor-hostels.trycloudflare.com | 524: A timeout occurred</title>\\n<meta charset=\"UTF-8\" />\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\\n<meta name=\"robots\" content=\"noindex, nofollow\" />\\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\\n<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\\n\\n\\n</head>\\n<body>\\n<div id=\"cf-wrapper\">\\n    <div id=\"cf-error-details\" class=\"p-0\">\\n        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\\n            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\\n              <span class=\"inline-block\">A timeout occurred</span>\\n              <span class=\"code-label\">Error code 524</span>\\n            </h1>\\n            <div>\\n               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=farm-bottom-mentor-hostels.trycloudflare.com\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\\n            </div>\\n            <div class=\"mt-3\">2025-03-22 14:27:22 UTC</div>\\n        </header>\\n        <div class=\"my-8 bg-gradient-gray\">\\n            <div class=\"w-240 lg:w-full mx-auto\">\\n                <div class=\"clearfix md:px-8\">\\n                  \\n<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    \\n    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    \\n  </div>\\n  <span class=\"md:block w-full truncate\">You</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    \\n    Browser\\n    \\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\\n</div>\\n\\n<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=farm-bottom-mentor-hostels.trycloudflare.com\" target=\"_blank\" rel=\"noopener noreferrer\">\\n    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    </a>\\n  </div>\\n  <span class=\"md:block w-full truncate\">Taipei</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=farm-bottom-mentor-hostels.trycloudflare.com\" target=\"_blank\" rel=\"noopener noreferrer\">\\n    Cloudflare\\n    </a>\\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\\n</div>\\n\\n<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    \\n    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    \\n  </div>\\n  <span class=\"md:block w-full truncate\">farm-bottom-mentor-hostels.trycloudflare.com</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    \\n    Host\\n    \\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\\n</div>\\n\\n                </div>\\n            </div>\\n        </div>\\n\\n        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\\n            <div class=\"clearfix\">\\n                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\\n                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\\n                    <p>The origin web server timed out responding to this request.</p>\\n                </div>\\n                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\\n                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\\n                          <h3 class=\"text-15 font-semibold mb-2\">If you\\'re a visitor of this website:</h3>\\n      <p class=\"mb-6\">Please try again in a few minutes.</p>\\n\\n      <h3 class=\"text-15 font-semibold mb-2\">If you\\'re the owner of this website:</h3>\\n      <p><span>The connection to the origin web server was made, but the origin web server timed out before responding. The likely cause is an overloaded background task, database or application, stressing the resources on your web server. To resolve, please work with your hosting provider or web development team to free up resources for your database or overloaded application.</span> <a rel=\"noopener noreferrer\" href=\"https://support.cloudflare.com/hc/en-us/articles/200171926-Error-524\">Additional troubleshooting information here.</a></p>\\n                </div>\\n            </div>\\n        </div>\\n\\n        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\\n  <p class=\"text-13\">\\n    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">92465c1d57005706</strong></span>\\n    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\\n    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\\n      Your IP:\\n      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\\n      <span class=\"hidden\" id=\"cf-footer-ip\">101.3.137.150</span>\\n      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\\n    </span>\\n    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=farm-bottom-mentor-hostels.trycloudflare.com\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\\n    \\n  </p>\\n  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\\n</div><!-- /.error-footer -->\\n\\n\\n    </div>\\n</div>\\n</body>\\n</html>')\n",
      "Requeuing...\n",
      "Exception in worker on attempt 1: raised InternalServerError('<!DOCTYPE html>\\n<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\\n<head>\\n\\n\\n<title>farm-bottom-mentor-hostels.trycloudflare.com | 524: A timeout occurred</title>\\n<meta charset=\"UTF-8\" />\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\\n<meta name=\"robots\" content=\"noindex, nofollow\" />\\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\\n<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\\n\\n\\n</head>\\n<body>\\n<div id=\"cf-wrapper\">\\n    <div id=\"cf-error-details\" class=\"p-0\">\\n        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\\n            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\\n              <span class=\"inline-block\">A timeout occurred</span>\\n              <span class=\"code-label\">Error code 524</span>\\n            </h1>\\n            <div>\\n               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=farm-bottom-mentor-hostels.trycloudflare.com\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\\n            </div>\\n            <div class=\"mt-3\">2025-03-22 14:27:25 UTC</div>\\n        </header>\\n        <div class=\"my-8 bg-gradient-gray\">\\n            <div class=\"w-240 lg:w-full mx-auto\">\\n                <div class=\"clearfix md:px-8\">\\n                  \\n<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    \\n    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    \\n  </div>\\n  <span class=\"md:block w-full truncate\">You</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    \\n    Browser\\n    \\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\\n</div>\\n\\n<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=farm-bottom-mentor-hostels.trycloudflare.com\" target=\"_blank\" rel=\"noopener noreferrer\">\\n    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    </a>\\n  </div>\\n  <span class=\"md:block w-full truncate\">Taipei</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=farm-bottom-mentor-hostels.trycloudflare.com\" target=\"_blank\" rel=\"noopener noreferrer\">\\n    Cloudflare\\n    </a>\\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\\n</div>\\n\\n<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    \\n    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    \\n  </div>\\n  <span class=\"md:block w-full truncate\">farm-bottom-mentor-hostels.trycloudflare.com</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    \\n    Host\\n    \\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\\n</div>\\n\\n                </div>\\n            </div>\\n        </div>\\n\\n        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\\n            <div class=\"clearfix\">\\n                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\\n                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\\n                    <p>The origin web server timed out responding to this request.</p>\\n                </div>\\n                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\\n                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\\n                          <h3 class=\"text-15 font-semibold mb-2\">If you\\'re a visitor of this website:</h3>\\n      <p class=\"mb-6\">Please try again in a few minutes.</p>\\n\\n      <h3 class=\"text-15 font-semibold mb-2\">If you\\'re the owner of this website:</h3>\\n      <p><span>The connection to the origin web server was made, but the origin web server timed out before responding. The likely cause is an overloaded background task, database or application, stressing the resources on your web server. To resolve, please work with your hosting provider or web development team to free up resources for your database or overloaded application.</span> <a rel=\"noopener noreferrer\" href=\"https://support.cloudflare.com/hc/en-us/articles/200171926-Error-524\">Additional troubleshooting information here.</a></p>\\n                </div>\\n            </div>\\n        </div>\\n\\n        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\\n  <p class=\"text-13\">\\n    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">92465c31836f8098</strong></span>\\n    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\\n    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\\n      Your IP:\\n      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\\n      <span class=\"hidden\" id=\"cf-footer-ip\">101.3.137.150</span>\\n      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\\n    </span>\\n    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=farm-bottom-mentor-hostels.trycloudflare.com\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\\n    \\n  </p>\\n  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\\n</div><!-- /.error-footer -->\\n\\n\\n    </div>\\n</div>\\n</body>\\n</html>')\n",
      "Requeuing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>context</th>\n",
       "      <th>hallucination_eval</th>\n",
       "      <th>hallucination_explanation</th>\n",
       "      <th>qa_eval</th>\n",
       "      <th>qa_explanation</th>\n",
       "      <th>summarization_eval</th>\n",
       "      <th>summarization_explanation</th>\n",
       "      <th>relevance_eval</th>\n",
       "      <th>relevance_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.</td>\n",
       "      <td>Where is the Eiffel Tower located?</td>\n",
       "      <td>The Eiffel Tower is located in Paris, France.</td>\n",
       "      <td>The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.</td>\n",
       "      <td>factual</td>\n",
       "      <td>EXPLANATION: The query asks for the location of the Eiffel Tower. The reference text states that the Eiffel Tower is located in Paris, France. The answer provided is \"The Eiffel Tower is located in Paris, France.\" This statement directly matches the information given in the reference text. Therefore, the answer is not a hallucination and is factually correct based on the provided reference text.\\n\\nLABEL: factual</td>\n",
       "      <td>correct</td>\n",
       "      <td>The question asks for the location of the Eiffel Tower. The reference text states, \"The Eiffel Tower is located in Paris, France.\" The answer provided is, \"The Eiffel Tower is located in Paris, France.\" The answer exactly matches the information provided in the reference text and fully answers the question. Therefore, the answer is correct.\\n\\nLABEL: correct\\n************</td>\n",
       "      <td>good</td>\n",
       "      <td>Here's a step-by-step explanation to evaluate the summary:\\n\\n1. **Comprehensiveness:** Does the summary capture the *essential* information from the original document? The original document is a question *asking* where the Eiffel Tower is. The summary *answers* that question. It provides the location ‚Äì Paris, France. Therefore, it *does* capture the essential information.\\n\\n2. **Conciseness:** Is the summary as short as it can be while still conveying the essential information? The summary is a single sentence and directly answers the question posed in the original document. There isn‚Äôt any extraneous information. It‚Äôs quite concise.\\n\\n3. **Coherence:** Does the summary make sense on its own? Is it logically structured? The summary is a simple statement of fact. It‚Äôs perfectly coherent; it doesn't require the original question to understand it.\\n\\n4. **Independence:** Does the summary stand alone, or does it heavily rely on the original document for context? While the summary *originates* from the question, it doesn't *require* the question to be understood. Someone reading only the summary would understand that the Eiffel Tower is in Paris, France. It's independent in the sense that it‚Äôs a complete thought.\\n\\nConsidering all these points, the summary effectively answers the question posed in the original document in a clear, concise, and self-contained manner.\\n\\nLABEL: good</td>\n",
       "      <td>relevant</td>\n",
       "      <td>The question asks for the location of the Eiffel Tower. The reference text explicitly states, \"The Eiffel Tower is located in Paris, France.\" This directly answers the question. Therefore, the reference text contains information relevant to answering the question.\\n\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.</td>\n",
       "      <td>How long is the Great Wall of China?</td>\n",
       "      <td>The Great Wall of China is approximately 13,171 miles (21,196 kilometers) long.</td>\n",
       "      <td>The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.</td>\n",
       "      <td>factual</td>\n",
       "      <td>The query asks for the length of the Great Wall of China. The reference text states the Great Wall is \"over 13,000 miles long\". The answer states the Great Wall is approximately 13,171 miles (21,196 kilometers) long.\\n\\nThe answer provides a more precise length than the reference text, but it does *not* contradict the reference text. The reference text says \"over 13,000 miles\", and 13,171 miles is indeed over 13,000 miles. The answer doesn't introduce any new information that wasn't implied or reasonably inferred from the reference text. Therefore, the answer is factual, even though it provides a more specific number.\\n\\nLABEL: factual</td>\n",
       "      <td>correct</td>\n",
       "      <td>The question asks for the length of the Great Wall of China. The reference text states the Great Wall is \"over 13,000 miles long\". The answer provides a more specific length of \"approximately 13,171 miles\". Since 13,171 miles is greater than 13,000 miles and provides a more precise answer to the question of length, the answer is consistent with and expands upon the information in the reference text. The answer fully addresses the question.\\n\\nLABEL: correct</td>\n",
       "      <td>good</td>\n",
       "      <td>Here's a step-by-step explanation of how to evaluate the summary against the original document, focusing on comprehensiveness, conciseness, coherence, and independence:\\n\\n1. **Comprehensiveness Check:** Does the summary answer the question posed in the original document? The original document asks \"How long is the Great Wall of China?\". The summary *does* provide a length. We need to consider if it provides *enough* information to satisfy the question. A single, specific length is a reasonable answer.\\n\\n2. **Conciseness Check:** Is the summary unnecessarily verbose? The summary is a single sentence stating the length. Given the directness of the original question, this is appropriately concise. There's no extraneous information.\\n\\n3. **Coherence Check:** Does the summary make sense on its own, and is the information presented logically? Yes, the statement \"The Great Wall of China is approximately 13,171 miles (21,196 kilometers) long\" is a clear and logical statement.\\n\\n4. **Independence Check:** Does the summary require the original document to be understood? No. The summary is self-contained; a reader doesn't need the original question to understand the information presented. It stands alone as a factual statement.\\n\\nConsidering all four criteria ‚Äì comprehensiveness, conciseness, coherence, and independence ‚Äì the summary effectively addresses the original document's question in a clear, brief, and standalone manner.\\n\\nLABEL: good</td>\n",
       "      <td>relevant</td>\n",
       "      <td>The question asks for the length of the Great Wall of China. The reference text explicitly states the length of the Great Wall of China: \"over 13,000 miles long.\" Therefore, the reference text directly provides information to answer the question.\\n\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.</td>\n",
       "      <td>What is the largest tropical rainforest?</td>\n",
       "      <td>The Amazon rainforest is the largest tropical rainforest in the world. It is home to the largest number of plant and animal species in the world.</td>\n",
       "      <td>The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.</td>\n",
       "      <td>factual</td>\n",
       "      <td>The query asks for the largest tropical rainforest. The reference text states that the Amazon rainforest is the largest tropical rainforest. The answer states the Amazon rainforest is the largest tropical rainforest *and* that it is home to the largest number of plant and animal species. While the first part of the answer is directly supported by the reference text, the claim about plant and animal species is *not* mentioned in the reference text. Therefore, that portion of the answer is an assumption not found within the provided text. However, the core answer to the question is correct as supported by the reference text. Since the answer isn't entirely based on the reference text, it contains information not explicitly stated in the reference text.\\n\\nLABEL: factual</td>\n",
       "      <td>correct</td>\n",
       "      <td>The question asks for the largest tropical rainforest. The reference text states that the Amazon rainforest is the largest tropical rainforest. The answer also states that the Amazon rainforest is the largest tropical rainforest. Additionally, the answer provides extra information about the Amazon rainforest having the largest number of plant and animal species. While this extra information isn't *required* to answer the question, it doesn't detract from the correctness of the answer. The core of the question is answered accurately and completely.\\n\\nLABEL: correct</td>\n",
       "      <td>bad</td>\n",
       "      <td>Here's how we can evaluate the summary against the original document, step-by-step:\\n\\n1. **Comprehensiveness:** Does the summary cover the key information presented (or implied) in the original document? The original document *asks a question* about the largest tropical rainforest. A comprehensive summary should *answer* that question. The summary *does* answer the question, identifying the Amazon rainforest. It also *adds* information about biodiversity, which, while related, isn't directly *asked* for. We need to consider if that addition is helpful or detracts from directness.\\n\\n2. **Conciseness:** Is the summary as short as possible while still conveying the essential information? The summary is two sentences long. Given that the original document is a single question, two sentences isn‚Äôt excessively long, but we should evaluate if both sentences are *necessary* to answer the question.\\n\\n3. **Coherence:** Does the summary make sense on its own? Is it logically organized? The summary flows reasonably well ‚Äì it identifies the rainforest and then adds a supporting fact.\\n\\n4. **Independence:** Can the summary be understood without needing to refer back to the original document? Yes, the summary is understandable on its own. It doesn‚Äôt rely on the original question for context.\\n\\nConsidering these points, the summary *answers* the question, but it *also* adds extra information that wasn't directly requested. While not *incorrect*, it slightly reduces the directness of answering the original query.\\n\\nLABEL: bad</td>\n",
       "      <td>relevant</td>\n",
       "      <td>The question asks for the largest tropical rainforest. The reference text states, \"The Amazon rainforest is the largest tropical rainforest in the world.\" This directly answers the question. Therefore, the reference text contains information relevant to answering the question.\\n\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.</td>\n",
       "      <td>Which is the highest mountain on Earth?</td>\n",
       "      <td>Mount Everest, standing at 29,029 feet (8,848 meters), is the highest mountain on Earth.</td>\n",
       "      <td>Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.</td>\n",
       "      <td>hallucinated</td>\n",
       "      <td>The query asks for the highest mountain on Earth. The reference text states Mount Everest is the highest mountain on Earth and provides its location. The answer also states Mount Everest is the highest mountain on Earth and *adds* the height: 29,029 feet (8,848 meters). While the statement that Mount Everest is the highest mountain is supported by the reference text, the *specific height* is not mentioned in the reference text. Therefore, the added height information is not explicitly supported by the provided text, even if it is a generally known fact. Since the answer includes information not present in the reference text, it can be considered a slight hallucination.\\n\\nLABEL: hallucinated</td>\n",
       "      <td>correct</td>\n",
       "      <td>The question asks for the highest mountain on Earth. The reference text states that Mount Everest is the highest mountain on Earth. The answer also states that Mount Everest is the highest mountain on Earth, and additionally provides its height. Since the answer correctly identifies the highest mountain and provides additional relevant information, it fully and correctly answers the question.\\n\\nLABEL: correct\\n************</td>\n",
       "      <td>good</td>\n",
       "      <td>Here's how we can evaluate the summary against the original document:\\n\\n1. **Comprehensiveness:** Does the summary cover all the *important* information present (or strongly implied) in the original document? The original document poses a question *about* the highest mountain. The summary *answers* that question. It provides the name of the highest mountain (Mount Everest). Therefore, it appears to be comprehensive *for the purpose of answering the question*.\\n\\n2. **Conciseness:** Is the summary as short as it can be while still conveying the necessary information? The summary is a single sentence and directly answers the question posed in the original document. It doesn't include extraneous details. It is reasonably concise.\\n\\n3. **Coherence:** Does the summary make sense on its own, and is the information presented logically? The summary is a clear and logical statement. It directly states a fact about Mount Everest. It's easy to understand even without the original question.\\n\\n4. **Independence:** Does the summary stand alone, or does it rely heavily on the original document for context? While the summary *originates* from the question in the original document, it doesn't *require* the original document to be understood. A reader encountering the summary alone would understand it.\\n\\nConsidering these four points, the summary effectively addresses the original document‚Äôs question in a clear, concise, and independent manner.\\n\\nLABEL: good</td>\n",
       "      <td>relevant</td>\n",
       "      <td>The question asks for the highest mountain on Earth. The reference text directly states \"Mount Everest is the highest mountain on Earth.\" This is a direct answer to the question. Therefore, the reference text contains information relevant to answering the question.\\n\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.</td>\n",
       "      <td>What is the longest river in the world?</td>\n",
       "      <td>The Nile River, at 6,650 kilometers (4,132 miles), is the longest river in the world.</td>\n",
       "      <td>The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.</td>\n",
       "      <td>factual</td>\n",
       "      <td>EXPLANATION: The query asks for the longest river in the world. The reference text states that the Nile is the longest river in the world and provides its length as approximately 6,650 km (4,132 miles). The answer states that the Nile River, at 6,650 kilometers (4,132 miles), is the longest river in the world. The answer directly reflects the information provided in the reference text, without adding any new or contradictory information. Therefore, the answer is based on the reference text and is not a hallucination.\\n\\nLABEL: factual</td>\n",
       "      <td>correct</td>\n",
       "      <td>The question asks for the longest river in the world. The reference text states that the Nile is the longest river in the world and provides its length. The answer also states that the Nile is the longest river in the world and includes the same length provided in the reference text. Therefore, the answer accurately and completely answers the question based on the provided reference.\\n\\nLABEL: correct</td>\n",
       "      <td>good</td>\n",
       "      <td>Here's how we can evaluate the summary against the original document, step-by-step:\\n\\n1. **Comprehensiveness:** Does the summary cover the key information requested in the original document? The original document *asks a question* about the longest river. The summary *answers* that question. It provides the name of the longest river (the Nile) and its length. Therefore, it appears to be comprehensive *in answering the question*.\\n\\n2. **Conciseness:** Is the summary as short as it can be while still conveying the essential information? The summary is a single sentence. Given the simple question, a shorter summary would likely omit crucial details (like the river's length). It appears concise.\\n\\n3. **Coherence:** Does the summary make sense on its own? Is it logically structured? The summary presents a clear statement of fact. It's easy to understand without needing the original question for context. It is coherent.\\n\\n4. **Independence:** Does the summary stand alone, or does it heavily rely on the original document for meaning? The summary *could* stand alone as a factual statement, even without knowing the original question. While the question prompted the information, the summary itself isn't *dependent* on it for understanding.\\n\\nConsidering all these points, the summary effectively and efficiently answers the question posed in the original document.\\n\\nLABEL: good</td>\n",
       "      <td>relevant</td>\n",
       "      <td>The question asks for the longest river in the world. The reference text explicitly states \"The Nile is the longest river in the world.\" This directly answers the question. Therefore, the reference text contains information relevant to answering the question.\\n\\nLABEL: relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                               reference  \\\n",
       "0                                                                                The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.   \n",
       "1                                                 The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.   \n",
       "2                       The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.   \n",
       "3                                       Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.   \n",
       "4  The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.   \n",
       "\n",
       "                                      input  \\\n",
       "0        Where is the Eiffel Tower located?   \n",
       "1      How long is the Great Wall of China?   \n",
       "2  What is the largest tropical rainforest?   \n",
       "3   Which is the highest mountain on Earth?   \n",
       "4   What is the longest river in the world?   \n",
       "\n",
       "                                                                                                                                              output  \\\n",
       "0                                                                                                      The Eiffel Tower is located in Paris, France.   \n",
       "1                                                                    The Great Wall of China is approximately 13,171 miles (21,196 kilometers) long.   \n",
       "2  The Amazon rainforest is the largest tropical rainforest in the world. It is home to the largest number of plant and animal species in the world.   \n",
       "3                                                           Mount Everest, standing at 29,029 feet (8,848 meters), is the highest mountain on Earth.   \n",
       "4                                                              The Nile River, at 6,650 kilometers (4,132 miles), is the longest river in the world.   \n",
       "\n",
       "                                                                                                                                                                                                 context  \\\n",
       "0                                                                                The Eiffel Tower is located in Paris, France. It was constructed in 1889 as the entrance arch to the 1889 World's Fair.   \n",
       "1                                                 The Great Wall of China is over 13,000 miles long. It was built over many centuries by various Chinese dynasties to protect against nomadic invasions.   \n",
       "2                       The Amazon rainforest is the largest tropical rainforest in the world. It covers much of northwestern Brazil and extends into Colombia, Peru and other South American countries.   \n",
       "3                                       Mount Everest is the highest mountain on Earth. It is located in the Mahalangur Himal sub-range of the Himalayas, straddling the border between Nepal and Tibet.   \n",
       "4  The Nile is the longest river in the world. It flows northward through northeastern Africa for approximately 6,650 km (4,132 miles) from its most distant source in Burundi to the Mediterranean Sea.   \n",
       "\n",
       "  hallucination_eval  \\\n",
       "0            factual   \n",
       "1            factual   \n",
       "2            factual   \n",
       "3       hallucinated   \n",
       "4            factual   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    hallucination_explanation  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                            EXPLANATION: The query asks for the location of the Eiffel Tower. The reference text states that the Eiffel Tower is located in Paris, France. The answer provided is \"The Eiffel Tower is located in Paris, France.\" This statement directly matches the information given in the reference text. Therefore, the answer is not a hallucination and is factually correct based on the provided reference text.\\n\\nLABEL: factual   \n",
       "1                                                                                                                                         The query asks for the length of the Great Wall of China. The reference text states the Great Wall is \"over 13,000 miles long\". The answer states the Great Wall is approximately 13,171 miles (21,196 kilometers) long.\\n\\nThe answer provides a more precise length than the reference text, but it does *not* contradict the reference text. The reference text says \"over 13,000 miles\", and 13,171 miles is indeed over 13,000 miles. The answer doesn't introduce any new information that wasn't implied or reasonably inferred from the reference text. Therefore, the answer is factual, even though it provides a more specific number.\\n\\nLABEL: factual   \n",
       "2  The query asks for the largest tropical rainforest. The reference text states that the Amazon rainforest is the largest tropical rainforest. The answer states the Amazon rainforest is the largest tropical rainforest *and* that it is home to the largest number of plant and animal species. While the first part of the answer is directly supported by the reference text, the claim about plant and animal species is *not* mentioned in the reference text. Therefore, that portion of the answer is an assumption not found within the provided text. However, the core answer to the question is correct as supported by the reference text. Since the answer isn't entirely based on the reference text, it contains information not explicitly stated in the reference text.\\n\\nLABEL: factual   \n",
       "3                                                                                The query asks for the highest mountain on Earth. The reference text states Mount Everest is the highest mountain on Earth and provides its location. The answer also states Mount Everest is the highest mountain on Earth and *adds* the height: 29,029 feet (8,848 meters). While the statement that Mount Everest is the highest mountain is supported by the reference text, the *specific height* is not mentioned in the reference text. Therefore, the added height information is not explicitly supported by the provided text, even if it is a generally known fact. Since the answer includes information not present in the reference text, it can be considered a slight hallucination.\\n\\nLABEL: hallucinated   \n",
       "4                                                                                                                                                                                                                                                EXPLANATION: The query asks for the longest river in the world. The reference text states that the Nile is the longest river in the world and provides its length as approximately 6,650 km (4,132 miles). The answer states that the Nile River, at 6,650 kilometers (4,132 miles), is the longest river in the world. The answer directly reflects the information provided in the reference text, without adding any new or contradictory information. Therefore, the answer is based on the reference text and is not a hallucination.\\n\\nLABEL: factual   \n",
       "\n",
       "   qa_eval  \\\n",
       "0  correct   \n",
       "1  correct   \n",
       "2  correct   \n",
       "3  correct   \n",
       "4  correct   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                qa_explanation  \\\n",
       "0                                                                                                                                                                                                       The question asks for the location of the Eiffel Tower. The reference text states, \"The Eiffel Tower is located in Paris, France.\" The answer provided is, \"The Eiffel Tower is located in Paris, France.\" The answer exactly matches the information provided in the reference text and fully answers the question. Therefore, the answer is correct.\\n\\nLABEL: correct\\n************   \n",
       "1                                                                                                                The question asks for the length of the Great Wall of China. The reference text states the Great Wall is \"over 13,000 miles long\". The answer provides a more specific length of \"approximately 13,171 miles\". Since 13,171 miles is greater than 13,000 miles and provides a more precise answer to the question of length, the answer is consistent with and expands upon the information in the reference text. The answer fully addresses the question.\\n\\nLABEL: correct   \n",
       "2  The question asks for the largest tropical rainforest. The reference text states that the Amazon rainforest is the largest tropical rainforest. The answer also states that the Amazon rainforest is the largest tropical rainforest. Additionally, the answer provides extra information about the Amazon rainforest having the largest number of plant and animal species. While this extra information isn't *required* to answer the question, it doesn't detract from the correctness of the answer. The core of the question is answered accurately and completely.\\n\\nLABEL: correct   \n",
       "3                                                                                                                                                  The question asks for the highest mountain on Earth. The reference text states that Mount Everest is the highest mountain on Earth. The answer also states that Mount Everest is the highest mountain on Earth, and additionally provides its height. Since the answer correctly identifies the highest mountain and provides additional relevant information, it fully and correctly answers the question.\\n\\nLABEL: correct\\n************   \n",
       "4                                                                                                                                                                         The question asks for the longest river in the world. The reference text states that the Nile is the longest river in the world and provides its length. The answer also states that the Nile is the longest river in the world and includes the same length provided in the reference text. Therefore, the answer accurately and completely answers the question based on the provided reference.\\n\\nLABEL: correct   \n",
       "\n",
       "  summarization_eval  \\\n",
       "0               good   \n",
       "1               good   \n",
       "2                bad   \n",
       "3               good   \n",
       "4               good   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              summarization_explanation  \\\n",
       "0                                                                                                                                            Here's a step-by-step explanation to evaluate the summary:\\n\\n1. **Comprehensiveness:** Does the summary capture the *essential* information from the original document? The original document is a question *asking* where the Eiffel Tower is. The summary *answers* that question. It provides the location ‚Äì Paris, France. Therefore, it *does* capture the essential information.\\n\\n2. **Conciseness:** Is the summary as short as it can be while still conveying the essential information? The summary is a single sentence and directly answers the question posed in the original document. There isn‚Äôt any extraneous information. It‚Äôs quite concise.\\n\\n3. **Coherence:** Does the summary make sense on its own? Is it logically structured? The summary is a simple statement of fact. It‚Äôs perfectly coherent; it doesn't require the original question to understand it.\\n\\n4. **Independence:** Does the summary stand alone, or does it heavily rely on the original document for context? While the summary *originates* from the question, it doesn't *require* the question to be understood. Someone reading only the summary would understand that the Eiffel Tower is in Paris, France. It's independent in the sense that it‚Äôs a complete thought.\\n\\nConsidering all these points, the summary effectively answers the question posed in the original document in a clear, concise, and self-contained manner.\\n\\nLABEL: good   \n",
       "1                                                                                 Here's a step-by-step explanation of how to evaluate the summary against the original document, focusing on comprehensiveness, conciseness, coherence, and independence:\\n\\n1. **Comprehensiveness Check:** Does the summary answer the question posed in the original document? The original document asks \"How long is the Great Wall of China?\". The summary *does* provide a length. We need to consider if it provides *enough* information to satisfy the question. A single, specific length is a reasonable answer.\\n\\n2. **Conciseness Check:** Is the summary unnecessarily verbose? The summary is a single sentence stating the length. Given the directness of the original question, this is appropriately concise. There's no extraneous information.\\n\\n3. **Coherence Check:** Does the summary make sense on its own, and is the information presented logically? Yes, the statement \"The Great Wall of China is approximately 13,171 miles (21,196 kilometers) long\" is a clear and logical statement.\\n\\n4. **Independence Check:** Does the summary require the original document to be understood? No. The summary is self-contained; a reader doesn't need the original question to understand the information presented. It stands alone as a factual statement.\\n\\nConsidering all four criteria ‚Äì comprehensiveness, conciseness, coherence, and independence ‚Äì the summary effectively addresses the original document's question in a clear, brief, and standalone manner.\\n\\nLABEL: good   \n",
       "2  Here's how we can evaluate the summary against the original document, step-by-step:\\n\\n1. **Comprehensiveness:** Does the summary cover the key information presented (or implied) in the original document? The original document *asks a question* about the largest tropical rainforest. A comprehensive summary should *answer* that question. The summary *does* answer the question, identifying the Amazon rainforest. It also *adds* information about biodiversity, which, while related, isn't directly *asked* for. We need to consider if that addition is helpful or detracts from directness.\\n\\n2. **Conciseness:** Is the summary as short as possible while still conveying the essential information? The summary is two sentences long. Given that the original document is a single question, two sentences isn‚Äôt excessively long, but we should evaluate if both sentences are *necessary* to answer the question.\\n\\n3. **Coherence:** Does the summary make sense on its own? Is it logically organized? The summary flows reasonably well ‚Äì it identifies the rainforest and then adds a supporting fact.\\n\\n4. **Independence:** Can the summary be understood without needing to refer back to the original document? Yes, the summary is understandable on its own. It doesn‚Äôt rely on the original question for context.\\n\\nConsidering these points, the summary *answers* the question, but it *also* adds extra information that wasn't directly requested. While not *incorrect*, it slightly reduces the directness of answering the original query.\\n\\nLABEL: bad   \n",
       "3                                                                         Here's how we can evaluate the summary against the original document:\\n\\n1. **Comprehensiveness:** Does the summary cover all the *important* information present (or strongly implied) in the original document? The original document poses a question *about* the highest mountain. The summary *answers* that question. It provides the name of the highest mountain (Mount Everest). Therefore, it appears to be comprehensive *for the purpose of answering the question*.\\n\\n2. **Conciseness:** Is the summary as short as it can be while still conveying the necessary information? The summary is a single sentence and directly answers the question posed in the original document. It doesn't include extraneous details. It is reasonably concise.\\n\\n3. **Coherence:** Does the summary make sense on its own, and is the information presented logically? The summary is a clear and logical statement. It directly states a fact about Mount Everest. It's easy to understand even without the original question.\\n\\n4. **Independence:** Does the summary stand alone, or does it rely heavily on the original document for context? While the summary *originates* from the question in the original document, it doesn't *require* the original document to be understood. A reader encountering the summary alone would understand it.\\n\\nConsidering these four points, the summary effectively addresses the original document‚Äôs question in a clear, concise, and independent manner.\\n\\nLABEL: good   \n",
       "4                                                                                                                                                    Here's how we can evaluate the summary against the original document, step-by-step:\\n\\n1. **Comprehensiveness:** Does the summary cover the key information requested in the original document? The original document *asks a question* about the longest river. The summary *answers* that question. It provides the name of the longest river (the Nile) and its length. Therefore, it appears to be comprehensive *in answering the question*.\\n\\n2. **Conciseness:** Is the summary as short as it can be while still conveying the essential information? The summary is a single sentence. Given the simple question, a shorter summary would likely omit crucial details (like the river's length). It appears concise.\\n\\n3. **Coherence:** Does the summary make sense on its own? Is it logically structured? The summary presents a clear statement of fact. It's easy to understand without needing the original question for context. It is coherent.\\n\\n4. **Independence:** Does the summary stand alone, or does it heavily rely on the original document for meaning? The summary *could* stand alone as a factual statement, even without knowing the original question. While the question prompted the information, the summary itself isn't *dependent* on it for understanding.\\n\\nConsidering all these points, the summary effectively and efficiently answers the question posed in the original document.\\n\\nLABEL: good   \n",
       "\n",
       "  relevance_eval  \\\n",
       "0       relevant   \n",
       "1       relevant   \n",
       "2       relevant   \n",
       "3       relevant   \n",
       "4       relevant   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                      relevance_explanation  \n",
       "0               The question asks for the location of the Eiffel Tower. The reference text explicitly states, \"The Eiffel Tower is located in Paris, France.\" This directly answers the question. Therefore, the reference text contains information relevant to answering the question.\\n\\nLABEL: relevant  \n",
       "1                                 The question asks for the length of the Great Wall of China. The reference text explicitly states the length of the Great Wall of China: \"over 13,000 miles long.\" Therefore, the reference text directly provides information to answer the question.\\n\\nLABEL: relevant  \n",
       "2  The question asks for the largest tropical rainforest. The reference text states, \"The Amazon rainforest is the largest tropical rainforest in the world.\" This directly answers the question. Therefore, the reference text contains information relevant to answering the question.\\n\\nLABEL: relevant  \n",
       "3              The question asks for the highest mountain on Earth. The reference text directly states \"Mount Everest is the highest mountain on Earth.\" This is a direct answer to the question. Therefore, the reference text contains information relevant to answering the question.\\n\\nLABEL: relevant  \n",
       "4                    The question asks for the longest river in the world. The reference text explicitly states \"The Nile is the longest river in the world.\" This directly answers the question. Therefore, the reference text contains information relevant to answering the question.\\n\\nLABEL: relevant  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from phoenix.evals import (\n",
    "    HallucinationEvaluator,\n",
    "    OpenAIModel,\n",
    "    QAEvaluator,\n",
    "    SummarizationEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    run_evals\n",
    ")\n",
    "\n",
    "# ÂòóË©¶ÂºïÂÖ• FactualityEvaluatorÔºåËã•‰∏çÂèØÁî®ÂâáË®≠ÁÇ∫ None\n",
    "try:\n",
    "    from phoenix.evals import FactualityEvaluator\n",
    "except ImportError:\n",
    "    print(\"FactualityEvaluator ‰∏çÂ≠òÂú®ÔºåÂ∞áË∑≥ÈÅéÊ≠§Ë©ï‰º∞Âô®„ÄÇ\")\n",
    "    FactualityEvaluator = None\n",
    "\n",
    "nest_asyncio.apply()  # NotebookÁí∞Â¢É‰∏≠ÈúÄË¶ÅËôïÁêÜÈùûÂêåÊ≠•Êìç‰Ωú\n",
    "\n",
    "# Âª∫Á´ã OpenAI Ê®°ÂûãÂØ¶‰æã\n",
    "eval_model = OpenAIModel(\n",
    "    model=\"o1\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "# ÂÆöÁæ©Ë©ï‰º∞Âô®\n",
    "hallucination_evaluator = HallucinationEvaluator(eval_model)\n",
    "qa_evaluator = QAEvaluator(eval_model)\n",
    "summarization_evaluator = SummarizationEvaluator(eval_model)\n",
    "if FactualityEvaluator is not None:\n",
    "    factuality_evaluator = FactualityEvaluator(eval_model)\n",
    "relevance_evaluator = RelevanceEvaluator(eval_model)\n",
    "\n",
    "# Ë™øÊï¥ DataFrame Ê†ºÂºèÔºöÂ∞á reference Ê¨Ñ‰ΩçË§áË£ΩÁÇ∫ contextÔºå‰∏¶Â∞á query Ëàá response ÂàÜÂà•ÊîπÂêçÁÇ∫ input Ëàá output\n",
    "df[\"context\"] = df[\"reference\"]\n",
    "df.rename(columns={\"query\": \"input\", \"response\": \"output\"}, inplace=True)\n",
    "assert all(column in df.columns for column in [\"output\", \"input\", \"context\", \"reference\"])\n",
    "\n",
    "# Ê∫ñÂÇôË©ï‰º∞Âô®ÂàóË°®ÔºöËã• FactualityEvaluator ÂèØÁî®ÔºåÂâáÂä†ÂÖ•ÂÆÉ\n",
    "evaluators = [\n",
    "    hallucination_evaluator,\n",
    "    qa_evaluator,\n",
    "    summarization_evaluator,\n",
    "]\n",
    "if FactualityEvaluator is not None:\n",
    "    evaluators.append(factuality_evaluator)\n",
    "evaluators.append(relevance_evaluator)\n",
    "\n",
    "# Âü∑Ë°åË©ï‰º∞ÔºåÂõûÂÇ≥ÁöÑ DataFrame È†ÜÂ∫èËàáË©ï‰º∞Âô®ÂàóË°®È†ÜÂ∫è‰∏ÄËá¥\n",
    "results = run_evals(\n",
    "    dataframe=df,\n",
    "    evaluators=evaluators,\n",
    "    provide_explanation=True\n",
    ")\n",
    "\n",
    "# Ê†πÊìö FactualityEvaluator ÊòØÂê¶ÂèØÁî®ÔºåËß£ÂåÖÂõûÂÇ≥ÁöÑÁµêÊûú\n",
    "if FactualityEvaluator is not None:\n",
    "    hallucination_eval_df, qa_eval_df, summarization_eval_df, factuality_eval_df, relevance_eval_df = results\n",
    "else:\n",
    "    hallucination_eval_df, qa_eval_df, summarization_eval_df, relevance_eval_df = results\n",
    "\n",
    "# Êï¥ÁêÜÁµêÊûú DataFrameÔºåÂä†ÂÖ•ÂêÑË©ï‰º∞Âô®ÁöÑÁµêÊûú\n",
    "results_df = df.copy()\n",
    "results_df[\"hallucination_eval\"] = hallucination_eval_df[\"label\"]\n",
    "results_df[\"hallucination_explanation\"] = hallucination_eval_df[\"explanation\"]\n",
    "results_df[\"qa_eval\"] = qa_eval_df[\"label\"]\n",
    "results_df[\"qa_explanation\"] = qa_eval_df[\"explanation\"]\n",
    "results_df[\"summarization_eval\"] = summarization_eval_df[\"label\"]\n",
    "results_df[\"summarization_explanation\"] = summarization_eval_df[\"explanation\"]\n",
    "if FactualityEvaluator is not None:\n",
    "    results_df[\"factuality_eval\"] = factuality_eval_df[\"label\"]\n",
    "    results_df[\"factuality_explanation\"] = factuality_eval_df[\"explanation\"]\n",
    "results_df[\"relevance_eval\"] = relevance_eval_df[\"label\"]\n",
    "results_df[\"relevance_explanation\"] = relevance_eval_df[\"explanation\"]\n",
    "\n",
    "# È°ØÁ§∫Ââç 5 Á≠ÜË≥áÊñô\n",
    "results_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b244f3-58bd-44fe-8576-af24bdfe0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = df.copy()\n",
    "results_df[\"hallucination_eval\"] = hallucination_eval_df[\"label\"]\n",
    "results_df[\"hallucination_explanation\"] = hallucination_eval_df[\"explanation\"]\n",
    "results_df[\"qa_eval\"] = qa_eval_df[\"label\"]\n",
    "results_df[\"qa_explanation\"] = qa_eval_df[\"explanation\"]\n",
    "\n",
    "results_df[\"summarization_eval\"] = summarization_eval_df[\"label\"]\n",
    "results_df[\"summarization_explanation\"] = summarization_eval_df[\"explanation\"]\n",
    "results_df[\"factuality_eval\"] = factuality_eval_df[\"label\"]\n",
    "results_df[\"factuality_explanation\"] = factuality_eval_df[\"explanation\"]\n",
    "results_df[\"relevance_eval\"] = relevance_eval_df[\"label\"]\n",
    "results_df[\"relevance_explanation\"] = relevance_eval_df[\"explanation\"]\n",
    "\n",
    "# È°ØÁ§∫Ââç 5 Á≠ÜË≥áÊñôÔºå‰∏¶Á¢∫‰øùÊ¨Ñ‰ΩçÂÖßÂÆπ‰∏çË¢´Êà™Êñ∑\n",
    "results_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
