{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389fcae9-ef18-49b6-9709-d1b4cd995943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import phoenix as px\n",
    "\n",
    "# 將 PHOENIX_COLLECTOR_ENDPOINT 指向本機實際 IP\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"http://192.168.1.122:6006\"\n",
    "\n",
    "client = px.Client()\n",
    "dataset = client.get_dataset(\n",
    "    name=\"my-chinese-ods-dataset\",\n",
    "    version_id=\"RGF0YXNldFZlcnNpb246OQ==\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb16d056-e708-42cc-b97c-72aa7ad20092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(id='RGF0YXNldDo3', version_id='RGF0YXNldFZlcnNpb246OQ==')\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7241a7df-9fb9-48de-964e-0fa04751585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_keys', 'as_dataframe', 'examples', 'from_dict', 'id', 'version_id']\n"
     ]
    }
   ],
   "source": [
    "print(dir(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d31ec3-6f6a-4ebd-b5f8-14604ea91050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 input  \\\n",
      "example_id                                               \n",
      "RGF0YXNldEV4YW1wbGU6NTA=      {'input': '艾菲爾鐵塔位於哪裡？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTE=       {'input': '中國的長城有多長？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTI=     {'input': '最大的熱帶雨林是什麼？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTM=    {'input': '地球上最高的山是哪一座？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTQ=    {'input': '世界上最長的河流是什麼？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTU=       {'input': '蒙娜麗莎是誰畫的？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTY=        {'input': '人體有幾塊骨頭？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTc=  {'input': '太陽系中最大的行星是哪一顆？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTg=  {'input': '《羅密歐與茱麗葉》是誰寫的？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTk=  {'input': '第一次登月是什麼時候發生的？ '}   \n",
      "\n",
      "                                                                     output  \\\n",
      "example_id                                                                    \n",
      "RGF0YXNldEV4YW1wbGU6NTA=                        {'output': '艾菲爾鐵塔位於法國巴黎。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTE=       {'output': '中國的長城長約 13,171 英里（21,196 公里）。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTI=   {'output': '亞馬遜雨林是世界上最大的熱帶雨林。它是世界上動植物種類最多的家園。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTM=  {'output': '珠穆朗瑪峰海拔 29,029 英尺（8,848 公尺），是地球上最高...   \n",
      "RGF0YXNldEV4YW1wbGU6NTQ=  {'output': '尼羅河全長 6,650 公里（4,132 英里），是世界上最長的河流...   \n",
      "RGF0YXNldEV4YW1wbGU6NTU=     {'output': '《蒙娜麗莎》是義大利文藝復興時期藝術家李奧納多·達文西的作品。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTY=                  {'output': '成年人的身體通常有 256 塊骨頭。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTc=                     {'output': '木星是我們太陽系中最大的行星。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTg=             {'output': '戲劇《羅密歐與茱麗葉》是威廉·莎士比亞創作的。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTk=           {'output': '第一次登月發生在 1969 年 7 月 20 日。 '}   \n",
      "\n",
      "                                                                   metadata  \n",
      "example_id                                                                   \n",
      "RGF0YXNldEV4YW1wbGU6NTA=  {'reference': '艾菲爾鐵塔位於法國巴黎。它建於 1889 年，作為 1889 ...  \n",
      "RGF0YXNldEV4YW1wbGU6NTE=  {'reference': '中國的長城長達 13,000 多英里。它是中國各個朝代歷經多個...  \n",
      "RGF0YXNldEV4YW1wbGU6NTI=  {'reference': '亞馬遜雨林是世界上最大的熱帶雨林。它覆蓋了巴西西北部的大部分地...  \n",
      "RGF0YXNldEV4YW1wbGU6NTM=  {'reference': '珠穆朗瑪峰是地球上最高的山峰。它位於喜馬拉雅山馬哈蘭古爾喜馬拉...  \n",
      "RGF0YXNldEV4YW1wbGU6NTQ=  {'reference': '尼羅河是世界上最長的河流。它向北流經非洲東北部，從布隆迪最遠的...  \n",
      "RGF0YXNldEV4YW1wbGU6NTU=  {'reference': '《蒙娜麗莎》是李奧納多達文西畫的。它被認為是義大利文藝復興時期...  \n",
      "RGF0YXNldEV4YW1wbGU6NTY=  {'reference': '人體有206塊骨頭。這些骨骼提供結構、保護器官、固定肌肉並儲存...  \n",
      "RGF0YXNldEV4YW1wbGU6NTc=  {'reference': '木星是我們太陽系中最大的行星。它是一顆氣態巨行星，質量是太陽系...  \n",
      "RGF0YXNldEV4YW1wbGU6NTg=  {'reference': '威廉·莎士比亞寫了《羅密歐與茱麗葉》。這是一場關於兩個不幸的年...  \n",
      "RGF0YXNldEV4YW1wbGU6NTk=  {'reference': '第一次登月發生在 1969 年。 1969 年 7 月 20 ...  \n"
     ]
    }
   ],
   "source": [
    "print(dataset.as_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03c979ad-59b0-4b6c-8422-12a21bfe5db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['input', 'output', 'metadata'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = dataset.as_dataframe()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e50329a-9afe-424d-a0d4-bd8dc40c6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"input\"] = df[\"input\"].apply(lambda x: x['input'])\n",
    "df[\"output\"] = df[\"output\"].apply(lambda x: x['output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b27210db-151d-4675-8b92-5e59fe8858c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_CUSTOM_TEMPLATE = '''\n",
    "    You are evaluating whether the output mentions any person's name, such as common first names, full names, or references to individuals.\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    [Question]: {input}\n",
    "    ************\n",
    "    [Response]: {output}\n",
    "    [END DATA]\n",
    "\n",
    "\n",
    "    Please focus on the tone of the response.\n",
    "    Your answer must be single word, either \"yes\" or \"no\"\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8db8434-8f26-4c32-82cf-f0ae88a13417",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'phoenix.experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mphoenix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m llm_classify  \u001b[38;5;66;03m# 這個是一定要的！\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 連接到 o1 模型\u001b[39;00m\n\u001b[1;32m      6\u001b[0m client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(\n\u001b[1;32m      7\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m     base_url\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_BASE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'phoenix.experimental'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from phoenix.experimental.evals import llm_classify  # 這個是一定要的！\n",
    "\n",
    "# 連接到 o1 模型\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "# 建立一個 function，讓 Phoenix 可以用這個 function 去呼叫 o1\n",
    "def call_o1_model(prompt: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o1\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.6\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "# 使用 llm_classify，把你的 dataset 丟進去分類\n",
    "positive_eval = llm_classify(\n",
    "    dataframe=df,\n",
    "    template=MY_CUSTOM_TEMPLATE,\n",
    "    model=call_o1_model  # 注意這裡！傳入剛剛自己寫的 function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e26d2ac3-200f-4d70-9737-732bda896308",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'phoenix.experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mphoenix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mphoenix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m llm_classify\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'phoenix.experimental'"
     ]
    }
   ],
   "source": [
    "from phoenix.experimental.models import OpenAIModel\n",
    "from phoenix.experimental.evals import llm_classify\n",
    "import openai\n",
    "import os\n",
    "\n",
    "model = OpenAIModel(model_name=\"o1\",temperature=0.6)\n",
    "positive_eval = llm_classify(\n",
    "    dataframe=df,\n",
    "    template= MY_CUSTOM_TEMPLATE,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a57edb-f8ac-4729-b29f-f828a23d7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phoenix Evals support using either strings or objects as templates\n",
    "MY_CUSTOM_TEMPLATE = \" ...\"\n",
    "MY_CUSTOM_TEMPLATE = PromptTemplate(\"This is a test {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3f54d-31b7-40ac-927c-304a411e003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an experiment\n",
    "from phoenix.experiments import run_experiment\n",
    "\n",
    "experiment = run_experiment(dataset, my_task, evaluators=evaluators)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
