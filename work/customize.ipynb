{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389fcae9-ef18-49b6-9709-d1b4cd995943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (8.12.0) and client (8.27.1) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import phoenix as px\n",
    "\n",
    "# 將 PHOENIX_COLLECTOR_ENDPOINT 指向本機實際 IP\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = \"http://192.168.1.122:6006\"\n",
    "\n",
    "client = px.Client()\n",
    "dataset = client.get_dataset(\n",
    "    name=\"my-chinese-ods-dataset\",\n",
    "    version_id=\"RGF0YXNldFZlcnNpb246OQ==\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ed3d9-4178-43fc-9146-d1ce9205b090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.27.1\n"
     ]
    }
   ],
   "source": [
    "import phoenix\n",
    "print(phoenix.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16d056-e708-42cc-b97c-72aa7ad20092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(id='RGF0YXNldDo3', version_id='RGF0YXNldFZlcnNpb246OQ==')\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241a7df-9fb9-48de-964e-0fa04751585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_keys', 'as_dataframe', 'examples', 'from_dict', 'id', 'version_id']\n"
     ]
    }
   ],
   "source": [
    "print(dir(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d31ec3-6f6a-4ebd-b5f8-14604ea91050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 input  \\\n",
      "example_id                                               \n",
      "RGF0YXNldEV4YW1wbGU6NTA=      {'input': '艾菲爾鐵塔位於哪裡？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTE=       {'input': '中國的長城有多長？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTI=     {'input': '最大的熱帶雨林是什麼？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTM=    {'input': '地球上最高的山是哪一座？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTQ=    {'input': '世界上最長的河流是什麼？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTU=       {'input': '蒙娜麗莎是誰畫的？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTY=        {'input': '人體有幾塊骨頭？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTc=  {'input': '太陽系中最大的行星是哪一顆？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTg=  {'input': '《羅密歐與茱麗葉》是誰寫的？ '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTk=  {'input': '第一次登月是什麼時候發生的？ '}   \n",
      "\n",
      "                                                                     output  \\\n",
      "example_id                                                                    \n",
      "RGF0YXNldEV4YW1wbGU6NTA=                        {'output': '艾菲爾鐵塔位於法國巴黎。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTE=       {'output': '中國的長城長約 13,171 英里（21,196 公里）。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTI=   {'output': '亞馬遜雨林是世界上最大的熱帶雨林。它是世界上動植物種類最多的家園。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTM=  {'output': '珠穆朗瑪峰海拔 29,029 英尺（8,848 公尺），是地球上最高...   \n",
      "RGF0YXNldEV4YW1wbGU6NTQ=  {'output': '尼羅河全長 6,650 公里（4,132 英里），是世界上最長的河流...   \n",
      "RGF0YXNldEV4YW1wbGU6NTU=     {'output': '《蒙娜麗莎》是義大利文藝復興時期藝術家李奧納多·達文西的作品。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTY=                  {'output': '成年人的身體通常有 256 塊骨頭。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTc=                     {'output': '木星是我們太陽系中最大的行星。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTg=             {'output': '戲劇《羅密歐與茱麗葉》是威廉·莎士比亞創作的。 '}   \n",
      "RGF0YXNldEV4YW1wbGU6NTk=           {'output': '第一次登月發生在 1969 年 7 月 20 日。 '}   \n",
      "\n",
      "                                                                   metadata  \n",
      "example_id                                                                   \n",
      "RGF0YXNldEV4YW1wbGU6NTA=  {'reference': '艾菲爾鐵塔位於法國巴黎。它建於 1889 年，作為 1889 ...  \n",
      "RGF0YXNldEV4YW1wbGU6NTE=  {'reference': '中國的長城長達 13,000 多英里。它是中國各個朝代歷經多個...  \n",
      "RGF0YXNldEV4YW1wbGU6NTI=  {'reference': '亞馬遜雨林是世界上最大的熱帶雨林。它覆蓋了巴西西北部的大部分地...  \n",
      "RGF0YXNldEV4YW1wbGU6NTM=  {'reference': '珠穆朗瑪峰是地球上最高的山峰。它位於喜馬拉雅山馬哈蘭古爾喜馬拉...  \n",
      "RGF0YXNldEV4YW1wbGU6NTQ=  {'reference': '尼羅河是世界上最長的河流。它向北流經非洲東北部，從布隆迪最遠的...  \n",
      "RGF0YXNldEV4YW1wbGU6NTU=  {'reference': '《蒙娜麗莎》是李奧納多達文西畫的。它被認為是義大利文藝復興時期...  \n",
      "RGF0YXNldEV4YW1wbGU6NTY=  {'reference': '人體有206塊骨頭。這些骨骼提供結構、保護器官、固定肌肉並儲存...  \n",
      "RGF0YXNldEV4YW1wbGU6NTc=  {'reference': '木星是我們太陽系中最大的行星。它是一顆氣態巨行星，質量是太陽系...  \n",
      "RGF0YXNldEV4YW1wbGU6NTg=  {'reference': '威廉·莎士比亞寫了《羅密歐與茱麗葉》。這是一場關於兩個不幸的年...  \n",
      "RGF0YXNldEV4YW1wbGU6NTk=  {'reference': '第一次登月發生在 1969 年。 1969 年 7 月 20 ...  \n"
     ]
    }
   ],
   "source": [
    "print(dataset.as_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c979ad-59b0-4b6c-8422-12a21bfe5db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['input', 'output', 'metadata'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = dataset.as_dataframe()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50329a-9afe-424d-a0d4-bd8dc40c6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"input\"] = df[\"input\"].apply(lambda x: x['input'])\n",
    "df[\"output\"] = df[\"output\"].apply(lambda x: x['output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27210db-151d-4675-8b92-5e59fe8858c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_CUSTOM_TEMPLATE = '''\n",
    "    You are evaluating whether the output mentions any person's name, such as common first names, full names, or references to individuals.\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    [Question]: {input}\n",
    "    ************\n",
    "    [Response]: {output}\n",
    "    [END DATA]\n",
    "\n",
    "\n",
    "    Please focus on the tone of the response.\n",
    "    Your answer must be single word, either \"yes\" or \"no\"\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8db8434-8f26-4c32-82cf-f0ae88a13417",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'reload_client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 使用 llm_classify，把你的 dataset 丟進去分類\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m OpenAIModel(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo1\u001b[39m\u001b[38;5;124m\"\u001b[39m,temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m positive_eval \u001b[38;5;241m=\u001b[39m \u001b[43mllm_classify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMY_CUSTOM_TEMPLATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcall_o1_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 注意這裡！傳入剛剛自己寫的 function\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrails\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrails\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcurrency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/phoenix/evals/classify.py:90\u001b[0m, in \u001b[0;36mdeprecate_dataframe_arg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind_partial(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     89\u001b[0m bound_args\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/phoenix/evals/classify.py:197\u001b[0m, in \u001b[0;36mllm_classify\u001b[0;34m(data, model, template, rails, data_processor, system_instruction, verbose, use_function_calling_if_available, provide_explanation, include_prompt, include_response, include_exceptions, max_retries, exit_on_error, run_sync, concurrency, progress_bar_format)\u001b[0m\n\u001b[1;32m    195\u001b[0m concurrency \u001b[38;5;241m=\u001b[39m concurrency \u001b[38;5;129;01mor\u001b[39;00m model\u001b[38;5;241m.\u001b[39mdefault_concurrency\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# clients need to be reloaded to ensure that async evals work properly\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload_client\u001b[49m()\n\u001b[1;32m    199\u001b[0m use_openai_function_call \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    200\u001b[0m     use_function_calling_if_available\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, OpenAIModel)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39msupports_function_calling\n\u001b[1;32m    203\u001b[0m )\n\u001b[1;32m    205\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    206\u001b[0m     openai_function_call_kwargs(rails, provide_explanation) \u001b[38;5;28;01mif\u001b[39;00m use_openai_function_call \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    207\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'reload_client'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from phoenix.evals import llm_classify, OpenAIModel\n",
    "\n",
    "\n",
    "rails = ['yes', 'no']\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "def call_o1_model(prompt: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o1\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.6\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "\n",
    "model = OpenAIModel(model=\"o1\",temperature=0.6)\n",
    "positive_eval = llm_classify(\n",
    "    data=df,\n",
    "    template=MY_CUSTOM_TEMPLATE,\n",
    "    model=call_o1_model,  \n",
    "    rails=rails, \n",
    "    concurrency=5 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a57edb-f8ac-4729-b29f-f828a23d7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phoenix Evals support using either strings or objects as templates\n",
    "MY_CUSTOM_TEMPLATE = \" ...\"\n",
    "MY_CUSTOM_TEMPLATE = PromptTemplate(\"This is a test {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3f54d-31b7-40ac-927c-304a411e003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an experiment\n",
    "from phoenix.experiments import run_experiment\n",
    "\n",
    "experiment = run_experiment(dataset, my_task, evaluators=evaluators)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
